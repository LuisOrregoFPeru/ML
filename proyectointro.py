import streamlit as st
from huggingface_hub import InferenceClient
import requests
from docx import Document
from datetime import date
from typing import List

"""
Aplicaci√≥n Streamlit que genera autom√°ticamente:
* Introducci√≥n (‚â•‚ÄØ9 p√°ginas A4, prosa, tercera persona, futuro indicativo, ‚â§‚ÄØ10 l√≠neas por p√°rrafo)
* 10 antecedentes de PubMed parafraseados (130‚ÄØpalabras c/u)
* Bases te√≥ricas
* Hip√≥tesis de investigaci√≥n y estad√≠sticas

üëâ¬†Ya **NO** depende de `openai`; emplea modelos de Hugging¬†Face v√≠a `InferenceClient`.
   - Modelo por defecto: *mistralai/Mistral‚Äë7B‚ÄëInstruct‚Äëv0.2* (puedes cambiarlo).
   - Se requiere un **HUGGINGFACE¬†API¬†TOKEN** (gu√°rdalo en *Secrets* o ingr√©salo en la barra lateral).
"""

# ---------------- Configuraci√≥n del modelo ---------------- #

def get_client(token: str, model_id: str = "mistralai/Mistral-7B-Instruct-v0.2") -> InferenceClient:
    if not token:
        st.error("Se necesita un token de Hugging¬†Face v√°lido.")
        st.stop()
    return InferenceClient(model=model_id, token=token)


def hf_generate(client: InferenceClient, prompt: str, max_tokens: int = 1024, temperature: float = 0.3) -> str:
    """Genera texto con el modelo¬†HF (formato instrucci√≥n)."""
    return client.text_generation(
        prompt,
        max_new_tokens=max_tokens,
        temperature=temperature,
        top_p=0.9,
        repetition_penalty=1.1,
    )

# ---------------- Funciones de negocio ---------------- #

def generate_introduction(client: InferenceClient, title: str, objective: str, word_target: int = 4500) -> str:
    prompt = f"""
Redacta una introducci√≥n de tesis acad√©mica con las siguientes caracter√≠sticas:
‚Ä¢ Extensi√≥n m√≠nima: {word_target} palabras (‚âà 9 p√°ginas A4).
‚Ä¢ Prosa, sin subt√≠tulos, tercera persona, tiempo futuro del modo indicativo.
‚Ä¢ M√°ximo 10 l√≠neas por p√°rrafo.
‚Ä¢ Secuencia de p√°rrafos exacta:
  1‚Äë2‚ÄØp Importancia + plausibilidad del problema.
  1‚Äë2‚ÄØp Impacto (mundo, Latinoam√©rica, Per√∫).
  1‚Äë2‚ÄØp Vac√≠os de literatura.
  1‚ÄØp Contribuci√≥n a ODS.
  1‚ÄØp Pregunta de investigaci√≥n (interrogativa).
  1‚ÄØp Justificaci√≥n te√≥rica.
  1‚ÄØp Justificaci√≥n pr√°ctica.
  1‚ÄØp Justificaci√≥n metodol√≥gica.
  1‚ÄØp Justificaci√≥n social.
Al final escribe la l√≠nea EXACTA "===ANTECEDENTES===" para indicar d√≥nde se insertar√°n los antecedentes.
T√≠tulo: {title}
Objetivo general: {objective}
"""
    return hf_generate(client, prompt, max_tokens=4096)


def paraphrase_abstract(client: InferenceClient, abstract: str, word_count: int = 130) -> str:
    prompt = (
        f"Parafrasea en espa√±ol acad√©mico el siguiente resumen en aproximadamente {word_count} palabras, evitando plagio:\n{abstract}"
    )
    return hf_generate(client, prompt, max_tokens=256, temperature=0.4)


def search_pubmed(query: str, n: int = 10) -> List[dict]:
    base = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    ids = requests.get(base + "esearch.fcgi", params={"db": "pubmed", "term": query, "retmax": n, "retmode": "json"}).json()["esearchresult"]["idlist"]
    items = []
    for pmid in ids:
        xml = requests.get(base + "efetch.fcgi", params={"db": "pubmed", "id": pmid, "retmode": "xml"}).text
        import re, html
        abstract = re.search(r"<AbstractText.*?>(.*?)</AbstractText>", xml, re.S)
        if not abstract:
            continue
        authors = re.findall(r"<LastName>(.*?)</LastName>.*?<Initials>(.*?)</Initials>", xml, re.S)
        year = re.search(r"<PubDate>.*?<Year>(\\d{4})</Year>", xml, re.S)
        if authors:
            first = f"{authors[0][0]}, {authors[0][1][0]}."
            cite = first + (" et al." if len(authors) > 3 else "")
        else:
            cite = "Autor desconocido"
        items.append({
            "cite": f"{cite} ({year.group(1) if year else 's.f.'})",
            "abstract": html.unescape(abstract.group(1))
        })
    return items[:n]


def build_antecedents(client: InferenceClient, pubs: List[dict]) -> str:
    paras = []
    for p in pubs:
        para = paraphrase_abstract(client, p["abstract"])
        paras.append(f"{p['cite']} {para}")
    return "\n\n".join(paras)


def generate_theoretical_bases(client: InferenceClient, title: str, objective: str) -> str:
    prompt = (
        "Redacta las bases te√≥ricas pertinentes a la pregunta de investigaci√≥n, incluyendo enfoques conceptuales y variables clave. "
        "Prosa acad√©mica, tercera persona, futuro indicativo.\n"
        f"T√≠tulo: {title}\nObjetivo general: {objective}"
    )
    return hf_generate(client, prompt, max_tokens=1024)


def generate_hypotheses(client: InferenceClient, objective: str) -> str:
    prompt = (
        "Formula la hip√≥tesis de investigaci√≥n y las hip√≥tesis estad√≠sticas (nula y alternativa) basadas en el siguiente objetivo general.\n"
        f"{objective}"
    )
    return hf_generate(client, prompt, max_tokens=256)


def build_docx(intro: str, antecedentes: str, bases: str, hyps: str) -> bytes:
    doc = Document()
    doc.add_heading("Proyecto de Tesis ‚Äì Secciones Generadas", 1)
    doc.add_heading("Introducci√≥n", 2)
    for p in intro.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Antecedentes", 2)
    for p in antecedentes.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Bases Te√≥ricas", 2)
    for p in bases.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Hip√≥tesis", 2)
    for p in hyps.split("\n"):
        doc.add_paragraph(p)

    from io import BytesIO
    buffer = BytesIO()
    doc.save(buffer)
    return buffer.getvalue()

# ---------------- Interfaz Streamlit ---------------- #

st.set_page_config(page_title="Generador de Introducciones de Tesis", layout="wide")
st.title("üìù Generador Autom√°tico de Introducciones de Tesis (sin OpenAI)")

with st.sidebar:
    st.header("Configuraci√≥n")
    hf_token = st.text_input("Hugging Face API Token", type="password")
    model_id = st.text_input("ID del modelo (HF Hub)", value="mistralai/Mistral-7B-Instruct-v0.2")
    title_input = st.text_input("T√≠tulo de la Investigaci√≥n")
    objective_input = st.text_area("Objetivo General")
    generate_btn = st.button("Generar Introducci√≥n")

if generate_btn:
    client = get_client(hf_token, model_id)

    with st.spinner("Generando introducci√≥n‚Ä¶"):
        intro = generate_introduction(client, title_input, objective_input)
    st.subheader("Introducci√≥n")
    st.markdown(intro)

    with st.spinner("Buscando antecedentes en PubMed‚Ä¶"):
        pubs = search_pubmed(title_input or objective_input)
        antecedents = build_antecedents(client, pubs)
    st.subheader("Antecedentes")
    st.markdown(antecedents)

    with st.spinner("Generando bases te√≥ricas‚Ä¶"):
        bases = generate_theoretical_bases(client, title_input, objective_input)
    st.subheader("Bases Te√≥ricas")
    st.markdown(bases)

    with st.spinner("Generando hip√≥tesis‚Ä¶"):
        hyps = generate_hypotheses(client, objective_input)
    st.subheader("Hip√≥tesis")
    st.markdown(hyps)

    docx_file = build_docx(intro, antecedents, bases, hyps)
    st.download_button(
        "Descargar DOCX",
        data=docx_file,
        file_name=f"Tesis_{date.today()}.docx",
        mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    )

st.markdown("""
---
### ¬øC√≥mo usar esta versi√≥n?
1. Obt√©n un **Hugging¬†Face¬†API¬†TOKEN** gratis en <https://huggingface.co/settings/tokens>.
2. Agr√©galo en *Secrets* de Streamlit Cloud o en la barra lateral.
3. Ingresa el t√≠tulo u objetivo general y pulsa *Generar Introducci√≥n*.
4. Descarga el documento `.docx` para editarlo.

> Puedes cambiar `model_id` por cualquier modelo instructivo en el Hub que admita tarea *text‚Äëgeneration* (p.‚ÄØej. `meta-llama/Meta-Llama-3-8B-Instruct`).
""")

