import streamlit as st
from huggingface_hub import InferenceClient
import requests
from docx import Document
from datetime import date
from typing import List

"""
Aplicaci√≥n Streamlit para generar introducciones de tesis SIN exponer tu clave:
* Introducci√≥n ‚â• 9 p√°ginas A4 (prosa, 3.¬™ persona, futuro indicativo)
* 10 antecedentes de PubMed parafraseados
* Bases te√≥ricas y hip√≥tesis

üö© **La clave se obtiene de los Secrets de Streamlit Cloud o del cuadro lateral.** No hay token hard-codeado.
"""

# ---------------- Token y modelo por defecto ---------------- #

DEFAULT_MODEL_ID = "mistralai/Mistral-7B-Instruct-v0.2"

# Intenta leer la clave desde los Secrets del deploy
DEFAULT_HF_TOKEN = st.secrets.get("HF_TOKEN", "")  # ‚Üê vac√≠o si no se ha configurado

# ---------------- Configuraci√≥n del cliente HF ---------------- #

def get_client(token: str | None = None, model_id: str = DEFAULT_MODEL_ID) -> InferenceClient:
    token = token or DEFAULT_HF_TOKEN
    if not token:
        st.error("‚ö†Ô∏è Debes proporcionar un Hugging Face API Token en Secrets o en el panel lateral.")
        st.stop()
    return InferenceClient(model=model_id, token=token)


def hf_generate(client: InferenceClient, prompt: str, max_tokens: int = 1024, temperature: float = 0.3) -> str:
    """Genera texto con el modelo HF (formato instrucci√≥n)."""
    return client.text_generation(
        prompt,
        max_new_tokens=max_tokens,
        temperature=temperature,
        top_p=0.9,
        repetition_penalty=1.1,
    )

# ---------------- Funciones de negocio ---------------- #

def generate_introduction(client: InferenceClient, title: str, objective: str, word_target: int = 4500) -> str:
    prompt = f"""
Redacta una introducci√≥n de tesis acad√©mica con las siguientes caracter√≠sticas:
‚Ä¢ Extensi√≥n m√≠nima: {word_target} palabras (‚âà 9 p√°ginas A4).
‚Ä¢ Prosa, sin subt√≠tulos, tercera persona, tiempo futuro del modo indicativo.
‚Ä¢ M√°ximo 10 l√≠neas por p√°rrafo.
‚Ä¢ Secuencia de p√°rrafos exacta:
  1-2 p Importancia + plausibilidad del problema.
  1-2 p Impacto (mundo, Latinoam√©rica, Per√∫).
  1-2 p Vac√≠os de literatura.
  1 p Contribuci√≥n a ODS.
  1 p Pregunta de investigaci√≥n (interrogativa).
  1 p Justificaci√≥n te√≥rica.
  1 p Justificaci√≥n pr√°ctica.
  1 p Justificaci√≥n metodol√≥gica.
  1 p Justificaci√≥n social.
Al final escribe la l√≠nea EXACTA "===ANTECEDENTES===".
T√≠tulo: {title}
Objetivo general: {objective}
"""
    return hf_generate(client, prompt, max_tokens=4096)


def paraphrase_abstract(client: InferenceClient, abstract: str, word_count: int = 130) -> str:
    prompt = (
        f"Parafrasea en espa√±ol acad√©mico el siguiente resumen en aproximadamente {word_count} palabras, evitando plagio:\n{abstract}"
    )
    return hf_generate(client, prompt, max_tokens=256, temperature=0.4)


def search_pubmed(query: str, n: int = 10) -> List[dict]:
    base = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    ids = requests.get(base + "esearch.fcgi", params={"db": "pubmed", "term": query, "retmax": n, "retmode": "json"}).json()["esearchresult"]["idlist"]
    items = []
    for pmid in ids:
        xml = requests.get(base + "efetch.fcgi", params={"db": "pubmed", "id": pmid, "retmode": "xml"}).text
        import re, html
        abstract = re.search(r"<AbstractText.*?>(.*?)</AbstractText>", xml, re.S)
        if not abstract:
            continue
        authors = re.findall(r"<LastName>(.*?)</LastName>.*?<Initials>(.*?)</Initials>", xml, re.S)
        year = re.search(r"<PubDate>.*?<Year>(\\d{4})</Year>", xml, re.S)
        if authors:
            first = f"{authors[0][0]}, {authors[0][1][0]}."
            cite = first + (" et al." if len(authors) > 3 else "")
        else:
            cite = "Autor desconocido"
        items.append({
            "cite": f"{cite} ({year.group(1) if year else 's.f.'})",
            "abstract": html.unescape(abstract.group(1))
        })
    return items[:n]


def build_antecedents(client: InferenceClient, pubs: List[dict]) -> str:
    return "\n\n".join(
        f"{p['cite']} {paraphrase_abstract(client, p['abstract'])}" for p in pubs
    )


def generate_theoretical_bases(client: InferenceClient, title: str, objective: str) -> str:
    prompt = (
        "Redacta las bases te√≥ricas pertinentes a la pregunta de investigaci√≥n, incluyendo enfoques conceptuales y variables clave. "
        "Prosa acad√©mica, tercera persona, futuro indicativo.\n"
        f"T√≠tulo: {title}\nObjetivo general: {objective}"
    )
    return hf_generate(client, prompt, max_tokens=1024)


def generate_hypotheses(client: InferenceClient, objective: str) -> str:
    prompt = (
        "Formula la hip√≥tesis de investigaci√≥n y las hip√≥tesis estad√≠sticas (nula y alternativa) basadas en el siguiente objetivo general.\n"
        f"{objective}"
    )
    return hf_generate(client, prompt, max_tokens=256)


def build_docx(intro: str, antecedentes: str, bases: str, hyps: str) -> bytes:
    doc = Document()
    doc.add_heading("Proyecto de Tesis ‚Äì Secciones Generadas", 1)
    doc.add_heading("Introducci√≥n", 2)
    for p in intro.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Antecedentes", 2)
    for p in antecedentes.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Bases Te√≥ricas", 2)
    for p in bases.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Hip√≥tesis", 2)
    for p in hyps.split("\n"):
        doc.add_paragraph(p)

    from io import BytesIO
    buffer = BytesIO()
    doc.save(buffer)
    return buffer.getvalue()

# ---------------- Interfaz Streamlit ---------------- #

st.set_page_config(page_title="Generador de Introducciones de Tesis", layout="wide")
st.title("üìù Generador Autom√°tico de Introducciones de Tesis (Hugging Face)")

with st.sidebar:
    st.header("Configuraci√≥n")
    hf_token = st.text_input("Hugging Face API Token", type="passwo
