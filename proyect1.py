import streamlit as st
import requests
from docx import Document
from typing import List
import textwrap

# ---------------- Configuraci√≥n por defecto ---------------- #
# Modo simple: sin modelo LLM ni tokens API

# ---------------- Cliente Hugging Face (desactivado) ---------------- #

def get_client(token=None, model_id=None):
    """Siempre retorna None para forzar el modo simple."""
    return None


def hf_generate(client, prompt: str, max_tokens: int = 1024, temperature: float = 0.3) -> str:
    """Wrapper que siempre llama al generador simple."""
    return simple_llm(prompt)

# ---------------- Modo simple ---------------- #

def simple_paragraph(text: str) -> str:
    """Ajusta el texto para no exceder ~100 caracteres por l√≠nea."""
    return textwrap.fill(text, width=100)


def simple_llm(prompt: str) -> str:
    """Genera texto placeholder cuando no hay modelo disponible."""
    placeholders = [
        "Se resaltar√° la trascendencia del fen√≥meno planteado y la pertinencia cient√≠fica de abordarlo.",
        "Se describir√° la magnitud del problema a escala global, regional y nacional, destacando sus repercusiones sanitarias y econ√≥micas.",
        "Se sintetizar√°n las principales brechas de conocimiento detectadas en la literatura, subrayando la necesidad de nuevos estudios.",
        "La investigaci√≥n contribuir√° al Objetivo de Desarrollo Sostenible relacionado con la salud y el bienestar.",
        "¬øEn qu√© medida el fen√≥meno descrito se asociar√° con las variables seleccionadas en el contexto propuesto?",
        "Desde el punto de vista te√≥rico, el estudio profundizar√° en los modelos conceptuales vigentes y propondr√° nuevas perspectivas.",
        "En el plano pr√°ctico, los hallazgos orientar√°n intervenciones basadas en evidencia para mejorar la situaci√≥n analizada.",
        "Metodol√≥gicamente, se emplear√° un dise√±o robusto que garantizar√° la validez y confiabilidad de los resultados obtenidos.",
        "El beneficio social radicar√° en la generaci√≥n de conocimiento aplicable que favorecer√° la calidad de vida de la poblaci√≥n implicada."
    ]
    return "\n\n".join(simple_paragraph(p) for p in placeholders)

# ---------------- Funciones principales ---------------- #

def generate_introduction(client, title: str, objective: str, word_target: int = 4500) -> str:
    prompt = f"""
Redacta una introducci√≥n de tesis acad√©mica con las siguientes caracter√≠sticas:
‚Ä¢ Extensi√≥n m√≠nima: {word_target} palabras (‚âà 9 p√°ginas A4).
‚Ä¢ Prosa, sin subt√≠tulos, tercera persona, tiempo futuro del modo indicativo.
‚Ä¢ M√°ximo 10 l√≠neas por p√°rrafo.
‚Ä¢ Secuencia de p√°rrafos exacta:
  1‚Äë2‚ÄØp Importancia + plausibilidad del problema.
  1‚Äë2‚ÄØp Impacto (mundo, Latinoam√©rica, Per√∫).
  1‚Äë2‚ÄØp Vac√≠os de literatura.
  1‚ÄØp Contribuci√≥n a ODS.
  1‚ÄØp Pregunta de investigaci√≥n (interrogativa).
  1‚ÄØp Justificaci√≥n te√≥rica.
  1‚ÄØp Justificaci√≥n pr√°ctica.
  1‚ÄØp Justificaci√≥n metodol√≥gica.
  1‚ÄØp Justificaci√≥n social.
Al final escribe la l√≠nea EXACTA "===ANTECEDENTES===".
T√≠tulo: {title}
Objetivo general: {objective}
"""
    return hf_generate(client, prompt)


def paraphrase_abstract(client, abstract: str, word_count: int = 130) -> str:
    """Devuelve texto gen√©rico en modo simple."""
    return simple_paragraph("Resumen disponible para consulta; se presentar√° de forma sint√©tica y libre de plagio en la versi√≥n final.")


def search_pubmed(query: str, n: int = 10) -> List[dict]:
    """Obtiene n res√∫menes de PubMed (sin token)."""
    base = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"
    ids = requests.get(base + "esearch.fcgi", params={"db": "pubmed", "term": query, "retmax": n, "retmode": "json"}).json()["esearchresult"]["idlist"]
    items = []
    for pmid in ids:
        xml = requests.get(base + "efetch.fcgi", params={"db": "pubmed", "id": pmid, "retmode": "xml"}).text
        import re, html
        abstract = re.search(r"<AbstractText.*?>(.*?)</AbstractText>", xml, re.S)
        if not abstract:
            continue
        authors = re.findall(r"<LastName>(.*?)</LastName>.*?<Initials>(.*?)</Initials>", xml, re.S)
        year = re.search(r"<PubDate>.*?<Year>(\\d{4})</Year>", xml, re.S)
        if authors:
            first = f"{authors[0][0]}, {authors[0][1][0]}."
            cite = first + (" et al." if len(authors) > 3 else "")
        else:
            cite = "Autor desconocido"
        items.append({
            "cite": f"{cite} ({year.group(1) if year else 's.f.'})",
            "abstract": html.unescape(abstract.group(1))
        })
    return items[:n]


def build_antecedents(client, pubs: List[dict]) -> str:
    return "\n\n".join(
        f"{p['cite']} {paraphrase_abstract(client, p['abstract'])}" for p in pubs
    ) or "Sin referencias disponibles."


def generate_theoretical_bases(client, title: str, objective: str) -> str:
    return simple_paragraph("Se desarrollar√°n los fundamentos conceptuales que sustentan la relaci√≥n entre las variables propuestas y se explicar√° el marco te√≥rico que guiar√° el an√°lisis.")


def generate_hypotheses(client, objective: str) -> str:
    return simple_paragraph("Hip√≥tesis de investigaci√≥n y estad√≠sticas ser√°n formuladas relacionando las variables primarias para demostrar la direcci√≥n y fuerza del efecto esperado.")


def build_docx(intro: str, antecedentes: str, bases: str, hyps: str) -> bytes:
    doc = Document()
    doc.add_heading("Proyecto de Tesis ‚Äì Secciones Generadas", 1)
    doc.add_heading("Introducci√≥n", 2)
    for p in intro.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Antecedentes", 2)
    for p in antecedentes.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Bases Te√≥ricas", 2)
    for p in bases.split("\n"):
        doc.add_paragraph(p)
    doc.add_page_break()

    doc.add_heading("Hip√≥tesis", 2)
    for p in hyps.split("\n"):
        doc.add_paragraph(p)

    from io import BytesIO
    buffer = BytesIO()
    doc.save(buffer)
    return buffer.getvalue()

# ---------------- Interfaz Streamlit ---------------- #

st.set_page_config(page_title="Generador de Introducciones de Tesis", layout="wide")
st.title("üìù Generador Autom√°tico de Introducciones de Tesis ‚Äì Solo Modo Simple")

with st.sidebar:
    st.header("Configuraci√≥n")
    title_input = st.text_input("T√≠tulo de la Investigaci√≥n")
    objective_input = st.text_area("Objetivo General")
    generate_btn = st.button("Generar Introducci√≥n")

if generate_btn:
    client = get_client()  # Siempre None

    with st.spinner("Generando introducci√≥n‚Ä¶"):
        intro = generate_introduction(client, title_input, objective_input)
    st.subheader("Introducci√≥n")
    st.markdown(intro)

    with st.spinner("Buscando antecedentes en PubMed‚Ä¶"):
        pubs = search_pubmed(title_input or objective_input) if (title_input or objective_input) else []
        antecedentes = build_antecedents(client, pubs)
    st.subheader("Antecedentes")
    st.markdown(antecedentes)

    with st.spinner("Generando bases te√≥ricas‚Ä¶"):
        bases = generate_theoretical_bases(client, title_input, objective_input)
    st.subheader("Bases Te√≥ricas")
    st.markdown(bases)

    with st.spinner("Generando hip√≥tesis‚Ä¶"):
        hyps = generate_hypotheses(client, objective
